---
title: Custom Voice を作成する - Speech サービス
titleSuffix: Azure Cognitive Services
description: 実際のデータをアップロードする準備ができたら、Custom Voice ポータルに移動します。 Custom Voice プロジェクトを作成するか、選択します。 このプロジェクトでは、実際の音声トレーニングに使用するデータとして適切な言語またはロケールと性別プロパティを共有する必要があります。
services: cognitive-services
author: erhopf
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/04/2019
ms.author: erhopf
ms.openlocfilehash: 449975a6f0b5799ce93dcb31f42e1a43a1d183f3
ms.sourcegitcommit: c385af80989f6555ef3dadc17117a78764f83963
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/04/2021
ms.locfileid: "111412135"
---
# <a name="create-and-use-your-voice-model"></a>音声モデルを作成して使用する

「[カスタム音声を作成するためのデータを準備する](how-to-custom-voice-prepare-data.md)」では、カスタム ニューラル音声および別の形式の要件をトレーニングするために使用できるさまざまなデータ型について学習しました。 データとボイス タレントの口述の準備ができたら、[Speech Studio](https://aka.ms/custom-voice-portal) へのアップロードを開始できます。 この記事では、Speech Studio ポータルを使用してカスタム ニューラル音声をトレーニングする方法について説明します。 カスタム ニューラル音声で[サポートされる言語](language-support.md#customization)を参照してください。

## <a name="prerequisites"></a>前提条件

* [カスタム ニューラル音声の概要](how-to-custom-voice.md)に関するページを完了する
* [カスタム音声を作成するためのデータを準備する](how-to-custom-voice-prepare-data.md)

## <a name="set-up-voice-talent"></a>ボイス タレントを設定する

ボイス タレントは個人または対象話者であり、その音声が録音され、ニューラル音声モデルの作成に使用されます。 音声を作成する前に、音声のペルソナを定義して、適切なボイス タレントを選択します。 音声サンプルの録音の詳細については、[チュートリアル](record-custom-voice-samples.md)を参照してください。

ニューラル音声をトレーニングするには、ボイス タレントのプロファイルと共に、自分の音声データがカスタム音声モデルのトレーニングに使用されることに関する同意をボイス タレントが録音したオーディオ ファイルを作成する必要があります。 録音スクリプトを準備するときは、以下の文を必ず含めてください。

**"I [state your first and last name] am aware that recordings of my voice will be used by [state the name of the company] to create and use a synthetic version of my voice." (私 [自分の姓名] は、私の音声の合成バージョンを作成して使用するために、私の音声が [会社名] によって使用されることを承知しています。)**
この文は、トレーニング データが同意の口述の音声と一致するかどうかを確認するために使用されます。 詳細については、[ボイス タレントの検証](/legal/cognitive-services/speech-service/custom-neural-voice/data-privacy-security-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)に関する記事を参照してください。

> [!NOTE]
> カスタム ニューラル音声を利用するためのアクセスには制限があります。 [責任ある AI の要件](/legal/cognitive-services/speech-service/custom-neural-voice/limited-access-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)について理解してから、[アクセスを申請](https://aka.ms/customneural)してください。 

次の手順では、ボイス タレントによる音声同意ファイルが準備されていることを前提としています。  [Speech Studio](https://aka.ms/custom-voice-portal) に移動してカスタム ニューラル音声プロジェクトを選択し、次の手順に従って、ボイス タレントのプロファイルを作成します。

1. **[音声合成]**  >  **[Custom Voice]**  >  **[プロジェクトの選択]**  >  **[ボイス タレントの設定]** に移動します。

2. **[ボイス タレントの追加]** をクリックします。

3. 次に、音声の特性を定義するために、使用する **[ターゲット シナリオ]** をクリックします。 **[音声の特性]** を記述します。

> [!NOTE]
> 指定するシナリオは、申請フォームで申請したものと一致している必要があります。

4. 次に、 **[ボイス タレントの口述のアップロード]** に移動し、指示に従って、事前に準備したボイス タレントの口述をアップロードします。

> [!NOTE]
> 口述は、録音環境や話し方のスタイルを含め、トレーニング データと同じ設定で録音するようにしてください。

5. 最後に、 **[確認して送信]** に移動して設定を確認し、 **[送信]** をクリックします。

## <a name="upload-your-datasets"></a>データセットをアップロードする

データをアップロードする準備ができたら、 **[トレーニング データの準備]** タブに移動し、最初のトレーニング セットを追加してデータをアップロードします。  トレーニング セットは、音声モデルのトレーニングに使用される一連の音声発話とそのマッピング スクリプトです。 トレーニング セットを使用すると、トレーニング データを整理することができます。 データの準備状況のチェックは、トレーニング セットごとに実行されます。 複数のデータセットをトレーニング セットにインポートできます。

トレーニング データを作成して確認するには、次の手順を実行します。

1. **[トレーニング データの準備]** タブで、 **[トレーニングセットの追加]** をクリックして **[名前]** と **[説明]** を入力し、 **[作成]** をクリックして新しいトレーニング セットを追加します。

   トレーニング セットが正常に作成されたら、データのアップロードを開始できます。 

2. データをアップロードするには、 **[データのアップロード]**  >  **[データ型の選択]**  >  **[データのアップロード]** をクリックし、 **[ターゲット トレーニング セットの指定]** をクリックしてデータセットの **[名前]** と **[説明]** を入力し、設定を確認して **[アップロード]** をクリックします。

> [!NOTE]
>- 重複したオーディオ名はトレーニングから削除されます。 選択したデータセット内の 1 つの .zip ファイルまたは複数の .zip ファイルに同じオーディオ名が含まれていないことを確認してください。 (オーディオ ファイルまたはスクリプト ファイル内の) 発話 ID が重複している場合、それらは拒否されます。
>- 以前のバージョンの Speech Studio でデータセットを作成した場合、そのデータセットを使用するには、事前にデータセットのトレーニング セットを指定する必要があります。 そうしないと、データセット名に感嘆符が付加され、そのデータセットを使用できなくなります。

アップロードする各データセットでは、選択したデータの種類の要件が満たされている必要があります。 データをアップロードする前に適切に書式設定することが重要です。これにより、カスタム ニューラル音声サービスによってデータが正確に処理されるようになります。 「[カスタム音声を作成するためのデータを準備する](how-to-custom-voice-prepare-data.md)」に移動し、データが正しく書式設定されていることを確認します。

> [!NOTE]
> - Standard サブスクリプション (S0) ユーザーは、5 個のデータセットを同時にアップロードできます。 制限に達した場合は、少なくとも 1 つのデータセットのインポートが終わるまで待機します。 その後、やり直してください。
> - サブスクリプションあたりのインポートできるデータセットの最大数は、Free サブスクリプション (F0) ユーザーの場合は .zip ファイル 10 個、Standard サブスクリプション (S0) ユーザーの場合は 500 個です。

**[アップロード]** ボタンを押すと、データセットが自動的に検証されます。 データ検証には、ファイル形式、サイズ、サンプリング レートを確認する、オーディオ ファイルの一連のチェックが含まれます。 エラーが見つかった場合は、修正して、もう一度送信します。 

データがアップロードされたら、トレーニング セットの詳細ビューで詳細を確認できます。 **[概要]** タブでは、各データセットの発音スコアとノイズ レベルをさらにチェックできます。 発音スコアの範囲は 0 ～ 100 です。 スコアが 70 未満の場合は、通常、音声のエラーまたはスクリプトの不一致を示しています。 アクセントが強いと発音スコアが下がることがあり、生成されるデジタル音声に影響します。

高い信号雑音比 (SNR) は、オーディオのノイズが低いことを示します。 一般に、専門スタジオでの録音によって、SNR が 50 以上に達するようにできます。 SNR が 20 未満のオーディオでは、生成される音声に明らかなノイズが含まれる可能性があります。

発音スコアが低い場合や SNR が悪い場合は、発話を録音し直すことを検討してください。 再録音できない場合は、それらの発話をデータセットから除外することを検討してください。

**[データの詳細]** では、トレーニング セットのデータの詳細を確認できます。 データに関する一般的な問題が発生した場合は、表示されたメッセージの指示に従って、トレーニング前に修正してください。

これらの問題は 3 つの種類に分類されます。 次の 3 つの表を参照して、それぞれのエラーの種類を確認します。

以下の表に示す最初の種類のエラーは、手動で修正する必要があります。そうしないと、これらのエラーを含むデータがトレーニング中に除外されます。 

| カテゴリ | 名前 | 説明 | 提案される解決策 |
| --------- | ----------- | ----------- | --------------------------- |
| スクリプト | 無効な区切り記号| これらのスクリプト行には、有効な区切り記号である TAB がありません: {}。| ID とコンテンツを区切るには、TAB キーを使用します。|
| スクリプト | 無効なスクリプト ID| スクリプト ID の形式が無効です。| スクリプト行 ID は数値である必要があります。|
| スクリプト | スクリプトの内容が重複している| 行 {} のスクリプトの内容が行 {} と重複しています。| スクリプト行の内容は一意である必要があります。|
| スクリプト | スクリプトの内容が長すぎる| スクリプト行の内容が最大の長さ (1000) を超えています。| スクリプト行の内容の長さは、1000 文字未満にする必要があります。|
| スクリプト | スクリプトと一致する音声がない| スクリプト行 ID と一致する音声がありません。| スクリプト行 ID は、オーディオ ID と一致している必要があります。|
| スクリプト | 有効なスクリプトがない| このデータセットで有効なスクリプトが見つかりませんでした。| 詳細な問題の一覧に従って、問題のあるスクリプト行を修正します。|
| オーディオ | オーディオと一致するスクリプトがない| オーディオ ファイルがスクリプト ID と一致しません。| Wav ファイル名は、スクリプト ファイル内の ID と一致している必要があります。|
| オーディオ | 無効なオーディオ形式| Wav ファイルの形式が無効であるため、読み取ることができません。| sox などのオーディオ ツールで wav ファイル形式を確認します。|
| オーディオ | サンプリング レートが低い| 音声のサンプリング レートが 16 KHz を下回っています。 | Wav ファイルのサンプリング レートは、16 KHz 以上である必要があります。 |
| オーディオ | 音声の長さが長すぎる| 音声の長さが 30 秒を超えています。| 長い音声を複数のファイルに分割して、それぞれが 15 秒未満になるようにします。|
| オーディオ | 有効な音声がない| このデータセットで有効な音声が見つかりませんでした。| 詳細な問題の一覧に従って、問題のある音声を修正します。|

以下の表に示されている 2 番目の種類のエラーは自動的に修正されますが、修正されたデータをダブルチェックすることをお勧めします。 

| カテゴリ | 名前 | 説明 | 提案される解決策 |
| --------- | ----------- | ----------- | --------------------------- |
| オーディオ | ステレオ音声 | TTS モデルのトレーニングに使用されるのは、ステレオ音声の 1 チャネルだけです。|     TTS の録音またはデータの準備でモノラルを使用します。 この音声はモノラルに変換されます。 正規化されたデータセットをダウンロードして確認します。|
| ボリューム | ボリュームのピークが範囲外 |ボリュームのピークが -3 dB (最大ボリュームの 70%) から -6 dB (50%) の範囲内にありません。 ただちに -4 dB (65%) に自動的に調整されます。|  録音中またはデータの準備時に、ボリュームのピークを適切な範囲に制御します。 この音声は、ピーク範囲に合わせて線形にスケーリングされます。 正規化されたデータセットをダウンロードして確認します。|
|不一致 | 最初の単語の前に長い無音が検出された | 最初の単語の前に長い無音が検出されました。| 冒頭の無音は 200 ミリ秒にトリミングされます。 正規化されたデータセットをダウンロードして確認します。 |
| 不一致 | 最後の単語の後に長い無音が検出された | 最後の単語の後に長い無音が検出されました。 | 最後の無音は 200 ミリ秒にトリミングされます。 正規化されたデータセットをダウンロードして確認します。 |
| 不一致 |冒頭の無音が短すぎる | 冒頭の無音が 100 ミリ秒より短くなってます。 | 冒頭の無音が 100 ミリ秒に延長されます。 正規化されたデータセットをダウンロードして確認します。 |
| 不一致 | 最後の無音が短すぎる | 最後の無音が 100 ミリ秒より短くなってます。 | 最後の無音が 100 ミリ秒に延長されます。 正規化されたデータセットをダウンロードして確認します。 |

以下の表に示されている 3 番目の種類のエラーは修正されませんが、これらのエラーを含むデータはトレーニング中に除外されず、トレーニングの品質に影響します。 より高品質のトレーニングを行う場合は、これらのエラーを手動で修正することをお勧めします。 

| カテゴリ | 名前 | 説明 | 提案される解決策 |
| --------- | ----------- | ----------- | --------------------------- |
| スクリプト | 数字 0-9 が含まれている| これらのスクリプト行には、数字 0-9 が含まれています。| スクリプト行に数字 0-9 が含まれています。 これらを正規化された単語に展開して、音声と一致させます。 たとえば、' 123 ' を「百二十三」にします。|
| スクリプト | 発音が混同される語 '{}' | スクリプトに発音が混同される単語が含まれています: '{}'。| 単語を実際の発音に展開します。 たとえば、「 {} 」のように入力します。|
| スクリプト | 質問の発話が少なすぎる| 質問のスクリプト行が、スクリプト行の合計の 1/6 未満です。| 音声フォントで質問の声調が正しく表現されるように、質問のスクリプト行がすべての行の 1/6 以上含まれている必要があります。|
| スクリプト | 感嘆の発話が少なすぎる| 感嘆のスクリプト行が、スクリプト行の合計の 1/6 未満です。| 音声フォントで感嘆の声調が正しく表現されるように、感嘆のスクリプト行がすべての行の 1/6 以上含まれている必要があります。|
| オーディオ| ニューラル音声のサンプリング レートが低い | 音声のサンプリング レートが 24 KHz を下回っています。|    Wav ファイルのサンプリング レートは、高品質のニューラル音声の場合は 24 KHz 以上である必要があります。|
| ボリューム | 全体的にボリュームが低すぎる | {} サンプルのボリュームが -18 dB (最大ボリュームの 10%) を下回っています。|     録音中またはデータの準備時に、ボリュームの平均レベルを適切な範囲に制御します。|
| ボリューム | ボリュームの切り捨て| ボリュームの切り捨てが {} で検出されました。| ボリュームのピーク値が切り捨てられないように、録音装置を調整します。|
| ボリューム | 冒頭の無音がクリーンではない | 最初の 100 ミリ秒の無音がクリーンではありません。 -40 dB (最大ボリュームの 1%) を超えるボリュームが検出されます。|    録音のノイズ フロア レベルを下げて、冒頭の 100 ミリ秒を無音のままにします。|
| ボリューム| 最後の無音がクリーンではない| 最後の 100 ミリ秒の無音がクリーンではありません。 -40 dB (最大ボリュームの 1%) を超えるボリュームが検出されます。|     録音のノイズ レベルを下げて、最後の 100 ミリ秒を無音のままにします。|
| 不一致 | スクリプトと音声の不一致が検出された| スクリプトと音声コンテンツの間に不一致があります。 |     スクリプトと音声コンテンツを調べて、それらが一致していることを確認し、ノイズ フロア レベルを制御します。 長い無音の長さを短縮するか、複数の発話に分割します。|
| 不一致 | 最初の単語の前に余分な音声出力が検出された |    最初の単語の前に余分な音声出力が検出されました。 また、最初の単語の前の冒頭の無音が短すぎることが原因である可能性もあります。|    スクリプトと音声コンテンツを調べて、それらが一致していることを確認し、ノイズ フロア レベルを制御します。 また、最初の単語の前の 100 ミリ秒の無音を残します。|
| 不一致 | 最後の単語の後に余分な音声出力が検出された| 最後の単語の後に余分な音声出力が検出されました。 また、最後の単語の後の無音が短すぎることが原因である可能性もあります。|    スクリプトと音声コンテンツを調べて、それらが一致していることを確認し、ノイズ フロア レベルを制御します。 また、最初の単語の後の 100 ミリ秒の無音を残します。|
| 不一致 | 信号対雑音比が低い | 音声の SNR レベルが {} dB より低くなっています。| 録音中またはデータ準備時に、音声のノイズ レベルを下げます。|
| 不一致 | 音声コンテンツの認識に失敗する | この音声の音声認識に失敗します。|  音声とスクリプトのコンテンツをチェックして、音声が有効な音声であり、スクリプトと一致していることを確認します。|

## <a name="train-your-custom-neural-voice-model"></a>カスタム ニューラル音声モデルをトレーニングする

データセットを検証したら、それを使用してカスタム ニューラル音声モデルを作成できます。

1. **[モデルのトレーニング]** タブで、 **[モデルのトレーニング]** をクリックし、アップロードしたデータを使用して音声モデルを作成します。

2. モデルとターゲット言語のニューラル トレーニング方法を選択します。

既定では、音声モデルはトレーニング データと同じ言語でトレーニングされます。 音声モデルのセカンダリ言語を作成する (プレビュー) ために選択することもできます。  カスタム ニューラル音声でサポートされる言語と言語間機能を確認します ([カスタマイズ用の言語](language-support.md#customization))。

3. 次に、トレーニングに使用するデータセットを選択し、話者ファイルを指定します。

>[!NOTE]
>- カスタム ニューラル音声を作成するには、少なくとも 300 個の発話を選択する必要があります。
>- ニューラル音声をトレーニングするには、ボイス タレントのプロファイルと共に、自分の音声データがカスタム音声モデルのトレーニングに使用されることをボイス タレントが承認している音声同意ファイルを指定する必要があります。 カスタム ニューラル音声を利用するためのアクセスには制限があります。 [責任ある AI の要件](/legal/cognitive-services/speech-service/custom-neural-voice/limited-access-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)について理解し、[こちらのアクセスを適用](https://aka.ms/customneural)してください。
>- このページでは、テスト用のスクリプトのアップロードを選択することもできます。 テスト スクリプトは、1 Mb 未満の txt ファイルである必要があります。 サポートされているエンコード形式は、ANSI/ASCII、UTF-8、UTF-8-BOM、UTF-16-LE、または UTF-16-BE です。 発話の段落ごとに、個別の音声になります。 すべての文を 1 つの音声に結合したい場合は、1 つの段落にします。

4. 次に、このモデルを識別しやすい **[名前]** と **[説明]** を入力します。

名前は慎重に選択します。 ここで入力する名前が、SSML 入力の一部としての音声合成の要求時に、音声を指定するために使用する名前になります。 アルファベット、数字、およびいくつかの区切り文字 (-、\_、(、) など) だけを使用できます。 ニューラル音声モデルごとに、異なる名前を使用します。

**[Description]\(説明)** フィールドの一般的な用途は、モデルの作成に使用されたデータセットの名前を記録することです。

5. 設定を確認し、 **[送信]** をクリックしてモデルのトレーニングを開始します。

> [!NOTE]
> 重複したオーディオ名はトレーニングから削除されます。 選択したデータセット内の複数の .zip ファイルに同じオーディオ名が含まれていないことを確認してください。

**[モデルのトレーニング]** の表に、この新しく作成されたモデルに対応する新しいエントリが表示されます。 この表には、次の状態も表示されます。処理中、成功、失敗。

表示される状態は、ここに示すように、ご自分のデータセットから音声モデルへの変換プロセスを反映しています。

| State | 意味 |
| ----- | ------- |
| 処理中 | 実際の音声モデルを作成中です。 |
| 成功 | 実際の音声モデルは作成が済み、デプロイ可能です。 |
| 失敗 | 未知のデータの問題やネットワークの問題など、さまざまな理由により、トレーニング中に音声モデルが失敗しました。 |

トレーニング期間は、トレーニングするデータ量によって異なります。 カスタム ニューラル音声をトレーニングするには、平均で約 40 コンピューティング時間かかります。 

> [!NOTE]
> カスタム ニューラル音声のトレーニングは無料ではありません。 [価格](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/)を確認してください。 Standard サブスクリプション (S0) ユーザーは、3 つの音声を同時にトレーニングできます。 制限に達した場合は、少なくとも 1 つの音声フォントのトレーニングが終わるまで待ってから、やり直します。 

6. モデルのトレーニングが正常に完了したら、モデルの詳細を確認できます。

トレーニングごとに、モデルのテストに役立つ 100 個のサンプル オーディオ ファイルが自動的に生成されます。 音声モデルが正常に作成されたら、展開して使用する前にテストすることができます。

音声の品質は、トレーニング データのサイズ、録音の品質、トランスクリプト ファイルの正確さ、トレーニング データに録音された音声が目的のユース ケースに合わせて設計された音声の性格とどの程度一致しているかなど、さまざまな要因に依存します。 [テクノロジの機能と制限、およびモデルの品質を向上させるためのベスト プラクティスの詳細については、こちらを確認してください](/legal/cognitive-services/speech-service/custom-neural-voice/characteristics-and-limitations-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)。 

## <a name="create-and-use-a-custom-neural-voice-endpoint"></a>カスタム ニューラル音声のエンドポイントを作成して使用する

音声モデルの作成とテストが正常に終了したら、カスタム Text-to-Speech エンドポイントに展開します。 その後は、REST API で Text-to-Speech 要求を行うときの通常のエンドポイントの代わりに、このエンドポイントを使います。 カスタム エンドポイントは、フォントを展開するときに使用したサブスクリプションからのみ呼び出すことができます。

カスタム ニューラル音声のエンドポイントを作成するには、次の手順を実行します。

1. **[モデルのデプロイ]** タブで、 **[モデルのデプロイ]** をクリックします。 
2. 次に、カスタム エンドポイントの **[名前]** と **[説明]** を入力します。
3. 次に、このエンドポイントに関連付ける音声モデルを選択します。 
4. 最後に、 **[デプロイ]** をクリックしてエンドポイントを作成します。

**[デプロイ]** をクリックすると、エンドポイントの表に新しいエンドポイントのエントリが表示されます。 新しいエンドポイントのインスタンス化には、数分かかることがあります。 展開の状態が **[Succeeded]\(成功\)** の場合、エンドポイントを使用する準備ができています。

常に使用するのでない場合は、エンドポイントを **中断** して **再開** することができます。 中断後にエンドポイントが再アクティブ化されるとき、エンドポイントの URL は同じままになるので、アプリのコードを変更する必要はありません。 

また、エンドポイントを新しいモデルに更新することもできます。 モデルを変更するには、必ず新しいモデルの名前を更新するモデルと同じにします。 

> [!NOTE]
>- Standard サブスクリプション (S0) ユーザーは、独自のカスタム ニューラル音声がそれぞれ使用される最大 50 個のエンドポイントを作成できます。
>- カスタム ニューラル音声を使用するには、音声モデルの名前を指定して、HTTP 要求に直接カスタム URI を使用し、同じサブスクリプションを使用して TTS サービスの認証を通過する必要があります。

ご自分のエンドポイントがデプロイされると、エンドポイント名はリンクとして表示されます。 リンクをクリックすると、エンドポイント キー、エンドポイントの URL、サンプル コードなど、ご自分のエンドポイントに固有の情報が表示されます。

カスタム エンドポイントの機能は、テキスト読み上げ要求に使用される標準のエンドポイントと同じです。  詳細については、[Speech SDK](./get-started-text-to-speech.md) または [REST API](rest-text-to-speech.md) に関する記事を参照してください。

また、使いやすい UI を使用して音声出力を微調整できるオンライン ツール [Audio Content Creation](https://speech.microsoft.com/audiocontentcreation) も提供しています。

## <a name="next-steps"></a>次のステップ

- [音声サンプルを録音する方法](record-custom-voice-samples.md)
- [Text-to-Speech API リファレンス](rest-text-to-speech.md)
- [Long Audio API](long-audio-api.md)